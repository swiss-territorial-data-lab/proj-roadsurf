{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import os, sys\n",
    "import time\n",
    "import logging, logging.config\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterstats import zonal_stats\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "import numpy as np\n",
    "import stat\n",
    "import math\n",
    "import matplotlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import misc_fct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as fp:\n",
    "    cfg = yaml.load(fp, Loader=yaml.FullLoader)['statistical_analysis.py']    #  [os.path.basename(__file__)]\n",
    "\n",
    "\n",
    "# Defitions of the functions\n",
    "\n",
    "\n",
    "# Definition of the constants\n",
    "DEBUG_MODE=cfg['debug_mode']\n",
    "CORRECT_BALANCE=cfg['correct_balance']\n",
    "BANDS=range(1,5)\n",
    "COUNT_THRESHOLD = 50\n",
    "\n",
    "PROCESSED=cfg['processed']\n",
    "PROCESSED_FOLDER=PROCESSED['processed_folder']\n",
    "FINAL_FOLDER=cfg['final_folder']\n",
    "\n",
    "## Inputs\n",
    "ROADS=PROCESSED_FOLDER + PROCESSED['input_files']['roads']\n",
    "TILES_DIR=PROCESSED_FOLDER + PROCESSED['input_files']['images']\n",
    "TILES_INFO=PROCESSED_FOLDER + PROCESSED['input_files']['tiles']\n",
    "\n",
    "written_files=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_values(polygons, tile, pixel_values, **kwargs):\n",
    "    '''\n",
    "    Extract the value of the raster pixels falling under the mask and save them in a dataframe.\n",
    "\n",
    "    - polygons: shapefile determining the zones where the pixels are extracted\n",
    "    - tile: path to the raster image\n",
    "    - pixel_values: dataframe to which the values for the pixels are going to be concatenated\n",
    "    - kwargs: additional arguments we would like to pass the dataframe of the pixels\n",
    "    '''\n",
    "    \n",
    "    # extract the geometry in GeoJSON format\n",
    "    geoms = polygons.geometry.values # list of shapely geometries\n",
    "\n",
    "    geoms = [mapping(geoms[0])]\n",
    "\n",
    "    # extract the raster values values within the polygon \n",
    "    with rasterio.open(tile) as src:\n",
    "        out_image, out_transform = mask(src, geoms, crop=True)\n",
    "\n",
    "    # no data values of the original raster\n",
    "    no_data=src.nodata\n",
    "\n",
    "    if no_data is None:\n",
    "        no_data=0\n",
    "        # print('The value of \"no data\" is set to 0 by default.')\n",
    "    \n",
    "    for band in BANDS:\n",
    "\n",
    "        # extract the values of the masked array\n",
    "        data = out_image[band-1]\n",
    "\n",
    "        # extract the the valid values\n",
    "        val = np.extract(data != no_data, data)\n",
    "        val_0 = np.extract(data == no_data, data)\n",
    "\n",
    "        # print(f'{len(val_0)} pixels equal to the no data value ({no_data}).')\n",
    "\n",
    "        d=pd.DataFrame({'pix_val':val, 'band_num': band, **kwargs})\n",
    "\n",
    "        pixel_values = pd.concat([pixel_values, d],ignore_index=True)\n",
    "\n",
    "    return pixel_values, no_data\n",
    "\n",
    "def get_df_stats(dataframe, col, results_dict = None, to_df = False):\n",
    "    '''\n",
    "    Get the min, max, mean, median, std and count of a column in a dataframe and send back a dict or a dataframe\n",
    "\n",
    "    - dataframe: dataframe from which the statistics will be calculated\n",
    "    - col: sting or list of string indicating the column(s) from which the statistics will be calculated\n",
    "    - result dict: dictionary for the results with the key 'min', 'max', 'mean', 'median', 'std', and 'count'\n",
    "    - to_df: results from dictionary to dataframe\n",
    "    '''\n",
    "\n",
    "    if results_dict==None:\n",
    "        results_dict={'min': [], 'max': [], 'mean': [], 'median': [], 'std': [], 'count': []}\n",
    "\n",
    "    results_dict['min'].append(dataframe[col].min())\n",
    "    results_dict['max'].append(dataframe[col].max())\n",
    "    results_dict['mean'].append(dataframe[col].mean())\n",
    "    results_dict['median'].append(dataframe[col].median())\n",
    "    results_dict['std'].append(dataframe[col].std())\n",
    "    results_dict['count'].append(dataframe[col].count())\n",
    "\n",
    "    if to_df:\n",
    "        results_df=pd.DataFrame(results_dict)\n",
    "        return results_df\n",
    "    else:\n",
    "        return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of the files\n",
    "roads=gpd.read_file(ROADS)\n",
    "tiles_info = gpd.read_file(TILES_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roads.columns)\n",
    "print(tiles_info.columns)\n",
    "roads.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG_MODE:\n",
    "    tiles_info=tiles_info[1:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roads[roads.is_valid==False].shape[0]!=0:\n",
    "       print(f\"There are {roads[roads.is_valid==False].shape[0]} invalid geometries for the roads.\")\n",
    "       sys.exit(1)          \n",
    "\n",
    "simplified_roads=roads.drop(columns=['ERSTELLUNG', 'ERSTELLU_1', 'HERKUNFT', 'HERKUNFT_J', 'HERKUNFT_M','KUNSTBAUTE', 'WANDERWEGE',\n",
    "              'VERKEHRSBE', 'BEFAHRBARK', 'EROEFFNUNG', 'STUFE', 'RICHTUNGSG', 'KREISEL', 'EIGENTUEME', 'VERKEHRS_1', 'NAME', 'TLM_STRASS', 'STRASSENNA', \n",
    "              'SHAPE_Leng', 'Width'])\n",
    "\n",
    "\n",
    "# to_file(PROCESSED_FOLDER + '/shapefiles_gpkg/test_invalid_geom.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_reproj=simplified_roads.to_crs(epsg=3857)\n",
    "tiles_info_reproj=tiles_info.to_crs(epsg=3857)\n",
    "\n",
    "fp_list=[]\n",
    "for tile_idx in tiles_info_reproj.index:\n",
    "        # Get the name of the tiles\n",
    "        x, y, z = tiles_info_reproj.loc[tile_idx,'id'].lstrip('(,)').rstrip('(,)').split(',')\n",
    "        im_name = z.lstrip() + '_' + x + '_' + y.lstrip() + '.tif'\n",
    "        im_path = os.path.join(TILES_DIR, im_name)\n",
    "        fp_list.append(im_path)\n",
    "\n",
    "tiles_info_reproj['filepath']=fp_list\n",
    "\n",
    "misc_fct.test_crs(roads_reproj.crs, tiles_info_reproj.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roads_reproj[roads_reproj.is_valid==False].shape[0]!=0:\n",
    "       print(f\"There are {roads_reproj[roads_reproj.is_valid==False].shape[0]} invalid geometries for the road after the reprojection.\")\n",
    "\n",
    "       print(\"Correction of the roads presenting an invalid geometry with a buffer of 0 m...\")\n",
    "       corrected_roads=roads_reproj.copy()\n",
    "       corrected_roads.loc[corrected_roads.is_valid==False,'geometry']=corrected_roads[corrected_roads.is_valid==False]['geometry'].buffer(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_roads=gpd.GeoDataFrame()\n",
    "for idx in tqdm(tiles_info_reproj.index, desc='Clipping roads'):\n",
    "\n",
    "    roads_to_tile = gpd.clip(corrected_roads, tiles_info_reproj.loc[idx,'geometry']).explode(index_parts=False)\n",
    "    roads_to_tile['tile']=tiles_info_reproj.loc[idx, 'title']\n",
    "\n",
    "    clipped_roads=pd.concat([clipped_roads, roads_to_tile], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corrected_roads.shape)\n",
    "print(clipped_roads.shape)\n",
    "print(tiles_info_reproj.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirpath=misc_fct.ensure_dir_exists(os.path.join(PROCESSED_FOLDER, 'shapefiles_gpkg'))\n",
    "\n",
    "# clipped_roads.to_file(os.path.join(dirpath, 'test_clipped_geom.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des statistiques de zone pour les routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Avec rasterstats.zonal_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_on_tile=clipped_roads[clipped_roads['tile']==tiles_info_reproj.loc[1,'title']]\n",
    "\n",
    "x, y, z = tiles_info_reproj.loc[1,'id'].lstrip('(,)').rstrip('(,)').split(',')\n",
    "im_name = z.lstrip() + '_' + x + '_' + y.lstrip() + '.tif'\n",
    "im_path = os.path.join(TILES_DIR, im_name)\n",
    "\n",
    "test=zonal_stats(roads_on_tile.iloc[0:1], im_path, stats=['min', 'max', 'mean', 'median','std','count'], band=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_stats=pd.DataFrame()\n",
    "\n",
    "for tile_idx in tqdm(tiles_info_reproj.index, desc='Calculating zonal statistics'):\n",
    "\n",
    "    roads_on_tile=clipped_roads[clipped_roads['tile']==tiles_info_reproj.loc[tile_idx,'title']]\n",
    "\n",
    "    # Get the path of the tiles\n",
    "    im_path=tiles_info_reproj.loc[tile_idx,'filepath']\n",
    "\n",
    "    roads_on_tile.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Calculation for each road on each band\n",
    "    for road_idx in roads_on_tile.index:\n",
    "\n",
    "        road=roads_on_tile.iloc[road_idx:road_idx+1]\n",
    "\n",
    "        if road.shape[0]>1:\n",
    "            print('More than one road is being tested.')\n",
    "            sys.exit(1)\n",
    "\n",
    "        for band_num in BANDS:\n",
    "\n",
    "            stats=zonal_stats(road, im_path, stats=['min', 'max', 'mean', 'median','std','count'], band=band_num, nodata=0)\n",
    "            stats_dict=stats[0]\n",
    "            stats_dict['band']=band_num\n",
    "            stats_dict['road_id']=road.loc[road_idx,'OBJECTID']\n",
    "            stats_dict['road_type']=road.loc[road_idx,'BELAGSART']\n",
    "            stats_dict['geometry']=road.loc[road_idx,'geometry']\n",
    "            stats_dict['tile_id']=tiles_info_reproj.loc[tile_idx,'id']\n",
    "\n",
    "            roads_stats = pd.concat([roads_stats, pd.DataFrame(stats_dict,index=[0])],ignore_index=True)\n",
    "\n",
    "roads_stats['mean']=roads_stats['mean'].round(1)\n",
    "roads_stats['std']=roads_stats['std'].round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_stats[roads_stats['road_type']==200]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Avec les statistiques des pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_values=pd.DataFrame()\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "\n",
    "roads_stats={'cover':[], 'band':[], 'road_id': [], 'road_type': [], 'geometry': [], 'min':[], 'max':[], 'mean':[], 'median':[], 'std':[], 'count':[]}\n",
    "\n",
    "for road_idx in tqdm(corrected_roads.index, desc='Extracting road statistics'):\n",
    "\n",
    "    # Get the characteristics of the road\n",
    "    objectid=corrected_roads.loc[road_idx, 'OBJECTID']\n",
    "    cover_type=corrected_roads.loc[road_idx, 'BELAGSART']\n",
    "    road=corrected_roads.loc[corrected_roads['OBJECTID'] == objectid,['OBJECTID', 'BELAGSART', 'geometry']]\n",
    "    road.reset_index(inplace=True, drop=True)\n",
    "    geometry = road.loc[0,'geometry'] if road.shape[0]==1 else MultiPolygon([road.loc[k,'geometry'] for k in road.index])\n",
    "\n",
    "    if objectid in roads_stats['road_id']:\n",
    "        continue\n",
    "    \n",
    "    # Get the corresponding tile(s)\n",
    "    misc_fct.test_crs(road.crs, tiles_info_reproj.crs)\n",
    "    intersected_tiles=gpd.overlay(tiles_info_reproj, road)\n",
    "\n",
    "    intersected_tiles.drop_duplicates(subset=['id'], inplace=True)\n",
    "    intersected_tiles.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    pixel_values=pd.DataFrame()\n",
    "\n",
    "    # Get the pixels for each tile\n",
    "    for tile_idx in intersected_tiles.index:\n",
    "\n",
    "        # Get the name of the tiles\n",
    "        im_path = intersected_tiles.loc[tile_idx,'filepath']\n",
    "        \n",
    "        pixel_values, no_data=get_pixel_values(road, im_path, pixel_values, road_id=objectid, road_cover=cover_type)\n",
    "\n",
    "    for band in BANDS:\n",
    "        pixels_subset=pixel_values[pixel_values['band_num']==band]\n",
    "\n",
    "        roads_stats['cover'].append(cover_type)\n",
    "        roads_stats['band'].append(band)\n",
    "        roads_stats['road_id'].append(objectid)\n",
    "        roads_stats['road_type'].append(cover_type)\n",
    "        roads_stats['geometry'].append(geometry)\n",
    "\n",
    "        roads_stats=get_df_stats(pixel_values, 'band_num', roads_stats)\n",
    "\n",
    "roads_stats=pd.DataFrame(roads_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_stats['mean']=roads_stats['mean'].round(1)\n",
    "roads_stats['std']=roads_stats['std'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roads_stats.shape[0]/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_stats_gdf=gpd.GeoDataFrame(roads_stats)\n",
    "\n",
    "dirpath=misc_fct.ensure_dir_exists(os.path.join(PROCESSED_FOLDER, 'shapefiles_gpkg'))\n",
    "\n",
    "# roads_stats_gdf.to_file(os.path.join(dirpath, 'roads_stats.shp'))\n",
    "# written_files.append('processed/shapefiles_gpkg/roads_stats.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_stats_df= roads_stats.drop(columns=['geometry'])\n",
    "\n",
    "print(roads_stats_df.tail(8))\n",
    "\n",
    "dirpath=misc_fct.ensure_dir_exists(os.path.join(PROCESSED_FOLDER,'tables'))\n",
    "\n",
    "\n",
    "roads_stats_df.to_csv(os.path.join(dirpath, 'stats_roads.csv'), index=False)\n",
    "written_files.append('processed/tables/road_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_stats_df.plot.hist(column=['count'], by='road_type', bins=50, title = 'Pixel count for each road')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_stats_filtered=roads_stats_df[roads_stats_df['count']>COUNT_THRESHOLD]\n",
    "\n",
    "print(f\"{roads_stats_df.shape[0]-roads_stats_filtered.shape[0]} on {roads_stats_df.shape[0]} were dropped because they contained less than {COUNT_THRESHOLD} pixels.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des statistiques par types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with the values of pixels on a road\n",
    "# cf https://gis.stackexchange.com/questions/260304/extract-raster-values-within-shapefile-with-pygeoprocessing-or-gdal\n",
    "\n",
    "pixel_values=pd.DataFrame()\n",
    "\n",
    "for tile_idx in tqdm(tiles_info_reproj.index, desc='Getting pixel values'):\n",
    "\n",
    "    roads_on_tile=clipped_roads[clipped_roads['tile']==tiles_info_reproj.loc[tile_idx,'title']]\n",
    "    tile = tiles_info_reproj.loc[tile_idx,'filepath']\n",
    "\n",
    "    for cover_type in roads_on_tile['BELAGSART'].unique().tolist():\n",
    "\n",
    "        road_shapes=roads_on_tile[roads_on_tile['BELAGSART']==cover_type]\n",
    "\n",
    "        pixel_values, no_data =get_pixel_values(road_shapes, tile, pixel_values, road_type=cover_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new table with a column per band (just reformatting the table)\n",
    "pixels_per_band={'road_type':[], 'band1':[], 'band2':[], 'band3':[], 'band4':[]}\n",
    "\n",
    "for cover_type in pixel_values['road_type'].unique().tolist():\n",
    "\n",
    "    for band in BANDS:\n",
    "\n",
    "        pixels_list=pixel_values.loc[(pixel_values['road_type']==cover_type) & (pixel_values['band_num']==band), ['pix_val']]['pix_val'].to_list()\n",
    "        pixels_per_band[f'band{band}'].extend(pixels_list)\n",
    "\n",
    "    # Following part to change. Probably, better handling of the no data would avoid this mistake\n",
    "    max_pixels=max(len(pixels_per_band['band1']), len(pixels_per_band['band2']), len(pixels_per_band['band3']), len(pixels_per_band['band4']))\n",
    "\n",
    "    for band in BANDS:\n",
    "        len_pixels_serie=len(pixels_per_band[f'band{band}'])\n",
    "\n",
    "        if len_pixels_serie!=max_pixels:\n",
    "\n",
    "            fill=[no_data]*max_pixels\n",
    "            pixels_per_band[f'band{band}'].extend(fill[len_pixels_serie:])\n",
    "\n",
    "            print(f'{max_pixels-len_pixels_serie} pixels were missing on the band {band} for the road cover {cover_type}. There were replaced with the value used of no data ({no_data})')\n",
    "\n",
    "\n",
    "    pixels_per_band['road_type'].extend([cover_type]*len(pixels_list))\n",
    "\n",
    "pixels_per_band=pd.DataFrame(pixels_per_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pixels_per_band['road_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the statistics of the pixel by band and by type of road cover\n",
    "\n",
    "cover_stats={'cover':[], 'band':[], 'min':[], 'max':[], 'mean':[], 'median':[], 'std':[], 'iq25':[], 'iq75':[], 'count':[]}\n",
    "\n",
    "for cover_type in pixel_values['road_type'].unique().tolist():\n",
    "\n",
    "    for band in BANDS:\n",
    "        pixels_subset=pixel_values[(pixel_values['band_num']==band) & (pixel_values['road_type']==cover_type)]\n",
    "\n",
    "        cover_stats['cover'].append(cover_type)\n",
    "        cover_stats['band'].append(band)\n",
    "\n",
    "        get_df_stats(pixels_subset, 'pix_val', cover_stats)\n",
    "        cover_stats['iq25'].append(pixels_subset['pix_val'].quantile(.25))\n",
    "        cover_stats['iq75'].append(pixels_subset['pix_val'].quantile(.75))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x-256 for x in cover_stats['max']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_stats['max']=[int(x) for x in cover_stats['max']] # Otherwise, the values get transformed to x-256 when converted in dataframe\n",
    "\n",
    "cover_stats_df=pd.DataFrame(cover_stats)\n",
    "cover_stats_df['mean']=cover_stats_df['mean'].round(1)\n",
    "cover_stats_df['std']=cover_stats_df['std'].round(1)\n",
    "\n",
    "print(cover_stats_df)\n",
    "\n",
    "dirpath=misc_fct.ensure_dir_exists(os.path.join(FINAL_FOLDER, 'tables') )\n",
    "\n",
    "cover_stats_df.to_csv(os.path.join(dirpath, 'statistics_roads_by_type.csv'), index=False)\n",
    "written_files.append('final/tables/statistics_roads_by_type.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORRECT_BALANCE:\n",
    "    print('Taking only a subset of the artifical roads and pixels to have a balanced dataset.')\n",
    "\n",
    "    natural_pixels=pixels_per_band[pixels_per_band['road_type']==200]\n",
    "    natural_stats=roads_stats_filtered[roads_stats_filtered['road_type']==200]\n",
    "\n",
    "    artificial_pixels=pixels_per_band[pixels_per_band['road_type']==100].reset_index(drop=True)\n",
    "    artificial_stats=roads_stats_filtered[roads_stats_filtered['road_type']==100].reset_index(drop=True)\n",
    "\n",
    "    artificial_pixels_subset=artificial_pixels.sample(frac=natural_pixels.shape[0]/artificial_pixels.shape[0], random_state=1)\n",
    "    artificial_stats_subset=artificial_stats.sample(frac=natural_stats.shape[0]/artificial_stats.shape[0], random_state=9)\n",
    "\n",
    "    # print(artificial_stats['mean'].mean()-artificial_stats_subset['mean'].mean())\n",
    "    # print(artificial_stats['median'].mean()-artificial_stats_subset['median'].mean())\n",
    "    # print(artificial_stats['std'].mean()-artificial_stats_subset['std'].mean())\n",
    "    # print(artificial_stats['count'].mean()-artificial_stats_subset['count'].mean())\n",
    "\n",
    "    # print(artificial_stats['mean'].std()-artificial_stats_subset['mean'].std())\n",
    "    # print(artificial_stats['median'].std()-artificial_stats_subset['median'].std())\n",
    "    # print(artificial_stats['std'].std()-artificial_stats_subset['std'].std())\n",
    "    # print(artificial_stats['count'].std()-artificial_stats_subset['count'].std())\n",
    "\n",
    "    pixels_per_band=pd.concat([artificial_pixels_subset, natural_pixels], ignore_index=True)\n",
    "    roads_stats_filtered=pd.concat([artificial_stats_subset,natural_stats], ignore_index=True)\n",
    "\n",
    "    balance='_balanced'\n",
    "\n",
    "else:\n",
    "    balance=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change the format to reader-frienldy\n",
    "BANDS=['NIR','R','G','B']\n",
    "pixels_per_band.rename(columns={'band1': 'NIR', 'band2': 'Red', 'band3': 'Green', 'band4': 'Blue'}, inplace=True)\n",
    "roads_stats_filtered.loc['band']=roads_stats_filtered['band'].replace({1: 'NIR', 2: 'R', 3: 'G', 4: 'B'})\n",
    "\n",
    "pixels_per_band['road_type']=pixels_per_band['road_type'].replace({100: 'artificial', 200: 'natural'})\n",
    "roads_stats_filtered['road_type']=roads_stats_filtered['road_type'].replace({100: 'artificial', 200: 'natural'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating boxplots...')\n",
    "\n",
    "dirpath_images=misc_fct.ensure_dir_exists(os.path.join(FINAL_FOLDER, 'images'))\n",
    "\n",
    "# The green bar in the boxplot is the median (cf. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.box.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot of the pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_pixel_bands=pixels_per_band.plot.box(by='road_type', title=f'Repartition of the values for the pixels', figsize=(15,8), grid=True)\n",
    "fig = bp_pixel_bands[0].get_figure()\n",
    "fig.savefig(os.path.join(dirpath_images, 'boxplot_pixel_in_bands.jpg'))\n",
    "written_files.append('final/images/boxplot_pixel_in_bands.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixels_subset.plot.box(column='pix_val', by=['road_type','band_num'], figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots of the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in BANDS:\n",
    "    roads_stats_subset=roads_stats_filtered[roads_stats_filtered['band']==band].drop(columns=['count', 'band', 'road_id'])\n",
    "    roads_stats_plot=roads_stats_subset.plot.box(by='road_type', figsize=(30,8), title=f'Boxplot of the statistics for the band {band}', grid=True)\n",
    "\n",
    "    # roads_stats_subset.boxplot(by='road_type', figsize=(30,8))\n",
    "\n",
    "    fig = roads_stats_plot[0].get_figure()\n",
    "    fig.savefig(os.path.join(dirpath_images, f'boxplot_stats_band_{band}.jpg'))\n",
    "    written_files.append(f'final/images/boxplot_stats_band_{band}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the parameters (bands and stats) successfully explain/distinguish the type of road cover?\n",
    " \n",
    "-> Are the clusters well defined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# cf. https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "print('Calculating PCAs...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evplot(ev):\n",
    "    '''\n",
    "    Implementation of Kaiser's rule and the Broken stick model (MacArthur, 1957) to determine the number of components to keep in the PCA.\n",
    "    https://www.mohanwugupta.com/post/broken_stick/ -> adapted for Python\n",
    "\n",
    "    - ev: eigenvalues\n",
    "    '''\n",
    "\n",
    "    n=len(ev)\n",
    "\n",
    "    # Broken stick model (MacArthur 1957)\n",
    "    j=np.arange(n)+1\n",
    "    bsm=[1/n]\n",
    "    for k in range(n-1):\n",
    "        bsm.append(bsm[k] + 1/(n-1-k))\n",
    "    bsm=[100*x/n for x in bsm]\n",
    "    bsm.reverse()\n",
    "\n",
    "    avg_ev=sum(ev)/len(ev)\n",
    "\n",
    "    # Plot figures\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "\n",
    "    ax = fig.add_subplot(2,1,1)\n",
    "    bx = fig.add_subplot(2,1,2)\n",
    "\n",
    "    ## Kaiser rule\n",
    "    ax.bar(j,ev)\n",
    "    ax.axhline(y=avg_ev, color='r', linestyle='-')\n",
    "\n",
    "    ## Broken stick model\n",
    "    bx.bar(j-0.25, ev, color='y', width=0.5)\n",
    "    bx.bar(j+0.25, bsm, color='r', width=0.5)\n",
    "\n",
    "    return bsm, fig\n",
    "    \n",
    "def determine_pc_num(ev, bsm):\n",
    "    '''\n",
    "    Determine the number of pc to keep\n",
    "    '''\n",
    "\n",
    "    pc_to_keep_kaiser=len([x for x in ev if x>sum(ev)/len(ev)])\n",
    "\n",
    "    pc_to_keep_bsm=len([x for x in ev if x>bsm[ev.tolist().index(x)]])\n",
    "\n",
    "    pc_to_keep=min(pc_to_keep_kaiser,pc_to_keep_bsm)\n",
    "\n",
    "    if pc_to_keep<2:\n",
    "        print(f'The number of components to keep was {pc_to_keep}. The number of components to keep is set to 1 and the number of components to plot is set to 2.')\n",
    "        pc_to_keep=1\n",
    "        pc_to_plot=2\n",
    "    elif pc_to_keep>10:\n",
    "        print(f'The number of components to keep and plot was {pc_to_keep}. It is set to a maximum limit of 10')\n",
    "        pc_to_keep=10\n",
    "        pc_to_plot=10\n",
    "    else:\n",
    "        pc_to_plot=pc_to_keep\n",
    "        print(f'The number of components to keep and plot is {pc_to_keep}.')\n",
    "\n",
    "    return pc_to_keep, pc_to_plot\n",
    "        \n",
    "def calculate_pca(dataset, features, to_describe,\n",
    "                dirpath_tables='tables',  dirpath_images='images',\n",
    "                file_pca_values='PCA_values.csv', file_pc_to_keep='PC_to_keep_evplot.jpg',\n",
    "                file_graph_ind='PCA_PC1{pc}_individuals.jpg', file_graph_feat='PCA_PC1{pc}_features.jpeg'):\n",
    "    '''\n",
    "    Calculate a PCA, determine the number of components to keep, plot the individuals and the variables along those components. The results as saved\n",
    "    as files.\n",
    "\n",
    "    Variables:\n",
    "    - dataset: dataset from which the PCA will be calculated\n",
    "    - features: decriptive variables of the dataset (must be numerical only)\n",
    "    - to_describe: explenatory variables or the variables to describe with the PCA (FOR NOW, ONLY ONE EXPLENATORY VARIALBE CAN BE PASSED)\n",
    "    - dirpath_tables: direcory for the tables\n",
    "    - dirpath_images: directory for the images\n",
    "    - file_pca_values: csv file where the coordoniates of the individuals after the PCA are saved\n",
    "    - file_pc_to_keep: image file where the graphs for the determination of the number of principal components to keep are saved\n",
    "    - file_graph_ind: image file where the graph for the individuals is saved\n",
    "    - file_graph_feat: image file where the graph for the features is saved\n",
    "    '''\n",
    "\n",
    "    written_files=[]\n",
    "\n",
    "    # 1. Define the variables and scale\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    x=dataset.loc[:,features].values\n",
    "    y=dataset.loc[:,to_describe].values\n",
    "\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "\n",
    "    # 2. Calculate the PCA\n",
    "    pca = PCA(n_components=len(features))\n",
    "\n",
    "    coor_PC = pca.fit_transform(x)\n",
    "\n",
    "    coor_PC_df = pd.DataFrame(data = coor_PC, columns = [f\"PC{k}\" for k in range(1,len(features)+1)])\n",
    "    results_PCA = pd.concat([coor_PC_df, dataset[to_describe]], axis = 1)\n",
    "\n",
    "    results_PCA.round(3).to_csv(os.path.join(dirpath_tables, file_pca_values), index=False)\n",
    "    written_files.append(file_pca_values)\n",
    "\n",
    "\n",
    "    # 3. Get the number of components to keep\n",
    "    eigenvalues=pca.explained_variance_\n",
    "    bsm, fig_pc_num = evplot(eigenvalues)\n",
    "\n",
    "    pc_to_keep, pc_to_plot = determine_pc_num(eigenvalues, bsm)\n",
    "\n",
    "    fig_pc_num.savefig(os.path.join(dirpath_images, file_pc_to_keep))\n",
    "    written_files.append(file_pc_to_keep)\n",
    "\n",
    "\n",
    "    # 4. Plot the graph of the individuals\n",
    "    expl_var_ratio=[round(x*100,2) for x in pca.explained_variance_ratio_.tolist()]\n",
    "\n",
    "    for pc in range(2,pc_to_plot+1):\n",
    "        locals={'pc': pc}\n",
    "        fig = plt.figure(figsize = (8,8))\n",
    "\n",
    "        ax = fig.add_subplot(1,1,1) \n",
    "        ax.set_xlabel(f'Principal Component 1 ({expl_var_ratio[0]}%)', fontsize = 15)\n",
    "        ax.set_ylabel(f'Principal Component {pc} ({expl_var_ratio[1]}%)', fontsize = 15)\n",
    "        ax.set_title('PCA for the values of the pixels on each band', fontsize = 20)\n",
    "\n",
    "        targets = dataset[to_describe].unique().tolist()\n",
    "        colors=[key[4:] for key in mcolors.TABLEAU_COLORS.keys()][pc_to_plot]\n",
    "        for target, color in zip(targets, colors):\n",
    "            indicesToKeep = results_PCA['road_type'] == target\n",
    "            ax.scatter(results_PCA.loc[indicesToKeep, 'PC1']\n",
    "                    , results_PCA.loc[indicesToKeep, f'PC{pc}']\n",
    "                    , c = color\n",
    "                    , s = 50)\n",
    "        ax.legend(targets)\n",
    "        ax.set_aspect(1)\n",
    "        ax.grid()\n",
    "\n",
    "        fig.savefig(os.path.join(dirpath_images, eval(f'f\"{file_graph_ind}\"', locals)))\n",
    "        written_files.append(eval(f'f\"{file_graph_ind}\"', locals))\n",
    "\n",
    "        # 5. Plot the graph of the variables\n",
    "        labels_column=[f'Principal component {k+1} ({expl_var_ratio[k]}%)' for k in range(len(features))]\n",
    "        coor_PC=pd.DataFrame(coor_PC, columns=labels_column)\n",
    "\n",
    "        loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "        # fig = px.scatter(coor_PC, x= f'Principal component 1 ({expl_var_ratio[0]}%)', y=f'Principal component {pc} ({expl_var_ratio[1]}%)', color=results_PCA['road_type'])\n",
    "        fig = px.scatter(pd.DataFrame(columns=labels_column), x = f'Principal component 1 ({expl_var_ratio[0]}%)', y=f'Principal component {pc} ({expl_var_ratio[1]}%)')\n",
    "\n",
    "        for i, feature in enumerate(features):\n",
    "            fig.add_shape(\n",
    "                type='line',\n",
    "                x0=0, y0=0,\n",
    "                x1=loadings[i, 0],\n",
    "                y1=loadings[i, 1]\n",
    "            )\n",
    "\n",
    "            fig.add_annotation(\n",
    "                x=loadings[i, 0],\n",
    "                y=loadings[i, 1],\n",
    "                ax=0, ay=0,\n",
    "                xanchor=\"center\",\n",
    "                yanchor=\"bottom\",\n",
    "                text=feature,\n",
    "            )\n",
    "\n",
    "        fig.update_yaxes(\n",
    "        scaleanchor = \"x\",\n",
    "        scaleratio = 1,\n",
    "        )\n",
    "\n",
    "        fig.write_image(os.path.join(dirpath_images, eval(f'f\"{file_graph_feat}\"', locals)))\n",
    "        fig.write_image(os.path.join(dirpath_images, eval(f'f\"{file_graph_feat}\"', locals).replace('jpeg','webp')))\n",
    "\n",
    "        written_files.append( eval(f'f\"{file_graph_feat}\"', locals))\n",
    "        written_files.append( eval(f'f\"{file_graph_feat}\"', locals).replace('jpeg','webp'))\n",
    "\n",
    "    return written_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pixels_per_band.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA of the pixel values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with function\n",
    "\n",
    "features = ['NIR', 'Red', 'Green', 'Blue']\n",
    "to_describe='road_type'\n",
    "\n",
    "dirpath_tables=misc_fct.ensure_dir_exists(os.path.join(FINAL_FOLDER, 'tables'))\n",
    "\n",
    "written_files_pca_pixels=calculate_pca(pixels_per_band, features, to_describe, dirpath_tables, dirpath_images, \n",
    "            f'PCA_pixel_values{balance}.csv', f'PCA_pixels_PC_to_keep_evplot{balance}.jpg',\n",
    "            'PCA_pixels_PC1{pc}_'+f'individuals{balance}.jpg', 'PCA_pixels_PC1{pc}_'+f'features{balance}.jpg')\n",
    "\n",
    "written_files.extend(written_files_pca_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA of the road stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in tqdm(BANDS, desc='Processing bands'):\n",
    "    roads_stats_filtered_subset=roads_stats_filtered[roads_stats_filtered['band']==band]\n",
    "\n",
    "    roads_stats_filtered_subset.reset_index(drop=True, inplace=True)\n",
    "    features = ['min', 'max', 'mean', 'std','median']\n",
    "\n",
    "    to_describe='road_type'\n",
    "\n",
    "    written_files_pca_stats=calculate_pca(roads_stats_filtered_subset, features, to_describe, dirpath_tables, dirpath_images, \n",
    "            f'PCA_stats_band_{band}_values{balance}.csv', f'PCA_stats_band_{band}_PC_to_keep_evplot{balance}.jpg',\n",
    "            'PCA_stats_PC1{pc}_'+f'band_{band}_individuals{balance}.jpg', 'PCA_stats_PC1{pc}_'+f'band_{band}_features{balance}.jpg')\n",
    "\n",
    "    written_files.extend(written_files_pca_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Checkout the written files: {written_files}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d832f3481d940cc3bb935f7c66bfbdcf68066e3553491dd3c1b68c49468b7cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
