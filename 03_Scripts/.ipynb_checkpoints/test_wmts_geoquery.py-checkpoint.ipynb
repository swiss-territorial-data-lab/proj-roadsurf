{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "736d2f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You know that ...\n",
    "import os, sys\n",
    "import requests\n",
    "import re\n",
    "import math\n",
    "import io\n",
    "import numpy\n",
    "import argparse\n",
    "import geopandas as gpd\n",
    "import yaml\n",
    "\n",
    "# That too ...\n",
    "from PIL import Image\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b827170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_thing( xml ):\n",
    "\n",
    "    \"\"\"\n",
    "    Overview :\n",
    "    This function is used to read the WMTS capabilities XML and translates it\n",
    "    into two arrays to facilitate extraction of data. The first returned array\n",
    "    contains the XML key path while the second, with corresponding index, gives\n",
    "    access to the keys content through a dictionary.\n",
    "    Parameter :\n",
    "    xml : XML content, as a string\n",
    "        Content of the fetch XML capabilities file from WMTS service.\n",
    "    Return :\n",
    "        The function returns the two composed arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise readers\n",
    "    xmlpath = []\n",
    "    xmldata = []\n",
    "\n",
    "    # Accumulator\n",
    "    acc = ''\n",
    "\n",
    "    # Current path\n",
    "    path = ''\n",
    "\n",
    "    # Current dictionary\n",
    "    dic = dict()\n",
    "\n",
    "    # Parsing XML string char by char\n",
    "    for char in xml:\n",
    "\n",
    "        # Avoid non-printable char\n",
    "        if ord( char ) >= 31:\n",
    "\n",
    "            # Case study\n",
    "            if char == '<':\n",
    "\n",
    "                # Check if content was detected between markers\n",
    "                if acc.strip():\n",
    "\n",
    "                    # Push content in current dictionary\n",
    "                    dic[\"inner\"] = acc\n",
    "\n",
    "                # Clear accumulator\n",
    "                acc = ''\n",
    "\n",
    "            elif char == '>':\n",
    "\n",
    "                # Extract first and last char\n",
    "                fstchar = acc[+0]\n",
    "                lstchar = acc[-1]\n",
    "\n",
    "                # Avoid special markers\n",
    "                if fstchar != '!' and fstchar != '?':\n",
    "\n",
    "                    # Case study\n",
    "                    if fstchar == '/':\n",
    "\n",
    "                        # Dump current path and associated dictionary\n",
    "                        xmlpath.append( path )\n",
    "                        xmldata.append( dic  )\n",
    "\n",
    "                        # Update current path\n",
    "                        path = '/'.join(path.split('/')[:-1])\n",
    "\n",
    "                    elif lstchar == '/':\n",
    "\n",
    "                        # Update current path\n",
    "                        path = path + '/' + acc.split(' ')[0]\n",
    "\n",
    "                        # Pre-process marker content\n",
    "                        acc = acc.replace( '\"', ' ' )\n",
    "                        acc = acc.replace( '=', ' ' )\n",
    "\n",
    "                        # Decompose marker content\n",
    "                        split = re.sub( ' +', ' ', acc.strip() ).split( ' ' )\n",
    "\n",
    "                        # Push marker content in current dictionary\n",
    "                        for index in range( 1, len( split ) - 1, 2 ):\n",
    "                            dic[split[index]] = split[index+1]\n",
    "\n",
    "                        # Dump current path and associated dictionary\n",
    "                        xmlpath.append( path )\n",
    "                        xmldata.append( dic  )\n",
    "\n",
    "                        # Update current path\n",
    "                        path = '/'.join(path.split('/')[:-1])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # Update current path\n",
    "                        path = path + '/' + acc.split(' ')[0]\n",
    "\n",
    "                # Clear accumulator\n",
    "                acc = ''\n",
    "\n",
    "                # Clear dictionary\n",
    "                dic = dict()\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Accumulate chars\n",
    "                acc = acc + char\n",
    "\n",
    "    # Return populated readers\n",
    "    return xmlpath, xmldata\n",
    "\n",
    "\n",
    "\n",
    "def detect_layer( xmlpath, xmldata, identifier ):\n",
    "\n",
    "    \"\"\"\n",
    "    Overview :\n",
    "    This function is responsible of locating the layer information in the XML\n",
    "    translation. The required layer information are then extracted and returned\n",
    "    through a dictionary with keys :\n",
    "        Identifier, Style, TileMatrixSet, ResourceURL\n",
    "    and their found corresponding values.\n",
    "    Parameters :\n",
    "    xmlpath : XML translation keys path\n",
    "        This array of keys path is the result of this script translation of the\n",
    "        XML content into an easy to access structure.\n",
    "    xmldata : XML translation keys content\n",
    "        This array of dictionaries, working with the xmlpath array index-wise,\n",
    "        is giving access to each key content.\n",
    "    identifier : target layer identifier\n",
    "        This string gives the identifier of the layer from which information are\n",
    "        extracted.\n",
    "    Return :\n",
    "        On success, the composed dictionary is returned. None otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Layer dictionary\n",
    "    layer = dict()\n",
    "\n",
    "    # Parsing path\n",
    "    for index in range( 0, len( xmlpath ) ):\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/Layer/ows:Identifier':\n",
    "            layer[\"Identifier\"] = xmldata[index][\"inner\"]\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/Layer/Style/ows:Identifier':\n",
    "            layer[\"Style\"] = xmldata[index][\"inner\"]\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/Layer/TileMatrixSetLink/TileMatrixSet':\n",
    "            layer[\"TileMatrixSet\"] = xmldata[index][\"inner\"]\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/Layer/ResourceURL':\n",
    "            layer[\"ResourceURL\"] = xmldata[index][\"template\"]\n",
    "\n",
    "        # Detect layer path\n",
    "        if xmlpath[index] == '/Capabilities/Contents/Layer':\n",
    "\n",
    "            # Detect target layer\n",
    "            if identifier == layer[\"Identifier\"]:\n",
    "\n",
    "                # Return populated dictionary\n",
    "                return layer\n",
    "\n",
    "    # Layer not found\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def detect_tile_matrix( xmlpath, xmldata, identifier ):\n",
    "\n",
    "    \"\"\"\n",
    "    Overview :\n",
    "    This function is responsible of reading the WMTS layer matrix set scales\n",
    "    information. It detects the matrix set associated with the target layer and\n",
    "    reads all the required information of each scale.\n",
    "    Parameters :\n",
    "    xmlpath : XML translation keys path\n",
    "        This array of keys path is the result of this script translation of the\n",
    "        XML content into an easy to access structure.\n",
    "    xmldata : XML translation keys content\n",
    "        This array of dictionaries, working with the xmlpath array index-wise,\n",
    "        is giving access to each key content.\n",
    "    identifier : target tile matrix identifier\n",
    "        This string has to gives the matrix set identifier associated with the\n",
    "        layer in which queries need to be performed.\n",
    "    Return :\n",
    "        This function returns the scales information through a series of arrays\n",
    "        were index act as scale id :\n",
    "            scale id, scale denominator, scale origin x and y, scale tile x and\n",
    "            y pixel size, matrix width and height\n",
    "        In case the matrix set is not found, all this array are returned with\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Identifier\n",
    "    detect_ident = None\n",
    "\n",
    "    # Stack element\n",
    "    scale_id         = None\n",
    "    scale_denom      = None\n",
    "    scale_origin_x   = None\n",
    "    scale_origin_y   = None\n",
    "    scale_pixel_x    = None\n",
    "    scale_pixel_y    = None\n",
    "    scale_mat_width  = None\n",
    "    scale_mat_height = None\n",
    "\n",
    "    # Initialise arrays\n",
    "    array_scale = []\n",
    "    array_denum = []\n",
    "    array_org_x = []\n",
    "    array_org_y = []\n",
    "    array_pix_x = []\n",
    "    array_pix_y = []\n",
    "    array_mat_x = []\n",
    "    array_mat_y = []\n",
    "\n",
    "    # Parsing path\n",
    "    for index in range( 0, len( xmlpath ) ):\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet/TileMatrix/ows:Identifier':\n",
    "            scale_id = int( xmldata[index][\"inner\"] )\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet/TileMatrix/ScaleDenominator':\n",
    "            scale_denom = float( xmldata[index][\"inner\"] )\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet/TileMatrix/TopLeftCorner':\n",
    "            buffer_decomp = xmldata[index][\"inner\"].split( ' ' )\n",
    "            scale_origin_x = float( buffer_decomp[0] )\n",
    "            scale_origin_y = float( buffer_decomp[1] )\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet/TileMatrix/TileWidth':\n",
    "            scale_pixel_x = int( xmldata[index][\"inner\"] )\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet/TileMatrix/TileHeight':\n",
    "            scale_pixel_y = int( xmldata[index][\"inner\"] )\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet/TileMatrix/MatrixWidth':\n",
    "            scale_mat_width = int( xmldata[index][\"inner\"] )\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet/TileMatrix/MatrixHeight':\n",
    "            scale_mat_height = int( xmldata[index][\"inner\"] )\n",
    "\n",
    "        # Detect tilematrix path\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet/TileMatrix':\n",
    "\n",
    "            # Push scale information on array\n",
    "            array_scale.append( scale_id         )\n",
    "            array_denum.append( scale_denom      )\n",
    "            array_org_x.append( scale_origin_x   )\n",
    "            array_org_y.append( scale_origin_y   )\n",
    "            array_pix_x.append( scale_pixel_x    )\n",
    "            array_pix_y.append( scale_pixel_y    )\n",
    "            array_mat_x.append( scale_mat_width  )\n",
    "            array_mat_y.append( scale_mat_height )\n",
    "\n",
    "        # Detect and push\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet/ows:Identifier':\n",
    "            detect_ident = xmldata[index][\"inner\"]\n",
    "\n",
    "        # Detect tilematrixset path\n",
    "        if xmlpath[index] == '/Capabilities/Contents/TileMatrixSet':\n",
    "\n",
    "            # Detect target tilematrixset\n",
    "            if detect_ident == identifier:\n",
    "\n",
    "                # Return composed arrays\n",
    "                return array_scale, array_denum, array_org_x, array_org_y, array_pix_x, array_pix_y, array_mat_x, array_mat_y\n",
    "\n",
    "            # Clear arrays\n",
    "            array_scale = []\n",
    "            array_denum = []\n",
    "            array_org_x = []\n",
    "            array_org_y = []\n",
    "            array_pix_x = []\n",
    "            array_pix_y = []\n",
    "            array_mat_x = []\n",
    "            array_mat_y = []        \n",
    "\n",
    "    # Tilematrixset not detected\n",
    "    return None, None, None, None, None, None, None, None\n",
    "\n",
    "\n",
    "\n",
    "def get_tile_by_bounding_box( param_url, param_bbox, param_size, param_output, param_tmp ):\n",
    "\n",
    "    \"\"\"\n",
    "    Overview :\n",
    "    This function is responsible of translating a tile bounding box and pixel\n",
    "    width into a _GeoTIFF_ image queried through a WMTS service, for now the\n",
    "    swisstopo SWISSIMAGE one.\n",
    "    The function starts by checking the geographical and pixel ratio to ensure\n",
    "    consistency and equal pixel size in both direction.\n",
    "    The function then searches the first WMTS scale that overshoot the tile\n",
    "    GSD. This scale is then used to create the list of WMTS tiles to query to\n",
    "    cover the full desired tile.\n",
    "    The WMTS tiles are then fetch using the swisstopo services and put into a\n",
    "    mosaic. This mosaic is then exported, in a temporary directory, in GeoTIFF\n",
    "    format. The GeoTIFF geographical information are computed based on the\n",
    "    WMTS scale value and tile index.\n",
    "    The exported mosaic is then cropped using GDAL binary (gdalwarp), through a\n",
    "    system call, to crop and resize it according to the provided bounding box\n",
    "    and pixel width and height.\n",
    "    The function clears all temporary elements it created in the temporary\n",
    "    directory.\n",
    "    Parameters :\n",
    "    param_url : Prepare query URL\n",
    "        This URL is used to perform the tile queries. The scale, tile x and y\n",
    "        index are replaced for each tile.\n",
    "    param_bbox : Float array\n",
    "        Desired tile bounding box : [ x_min, y_min, x_max, y_max ].\n",
    "    param_size : Integer array\n",
    "        Pixel width and height of the desired tile : [ w, h ].\n",
    "    param_output : String\n",
    "        Tile GeoTIFF exportation path.\n",
    "    param_tmp : String\n",
    "        Path of the temporary directory to use.\n",
    "    Return : Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if target file is already there\n",
    "    if os.path.isfile( param_output ):\n",
    "\n",
    "        # Display message\n",
    "        print( f'Information : file {os.path.basename(param_output)} already exists - Skipping' )\n",
    "\n",
    "        # Abort query\n",
    "        return\n",
    "\n",
    "    # Check ratio\n",
    "    if round( ( param_bbox[2] - param_bbox[0] ) / ( param_bbox[3] - param_bbox[1] ), 2 ) != round( param_size[0] / param_size[1], 2 ):\n",
    "\n",
    "        # Display message\n",
    "        print( 'Error : inconsistent ratio' )\n",
    "\n",
    "        # Abort procedure\n",
    "        sys.exit( 1 )\n",
    "\n",
    "\n",
    "    # Compute pixel size\n",
    "    pixel_size = ( param_bbox[2] - param_bbox[0] ) / param_size[0]\n",
    "\n",
    "    # Initialise optimal scale\n",
    "    optimal_scale = -1\n",
    "\n",
    "    # Initialise search\n",
    "    search_scale = min_scale_service\n",
    "\n",
    "    # Search optimal scale\n",
    "    while ( search_scale <= max_scale_service ) and ( optimal_scale < 0 ):\n",
    "\n",
    "        # Compute scale pixel size\n",
    "        scale_pixel_size = denominator_service[search_scale] * 0.28e-3\n",
    "\n",
    "        # Detect optimal scale\n",
    "        if ( scale_pixel_size <= pixel_size ) or ( search_scale == max_scale_service ):\n",
    "\n",
    "            # Assign optimal scale\n",
    "            optimal_scale = search_scale\n",
    "\n",
    "        # Next scale\n",
    "        search_scale = search_scale + 1\n",
    "\n",
    "\n",
    "    # Extract scale specific information\n",
    "    scale_pixel_size    = denominator_service[optimal_scale] * 0.28e-3\n",
    "    scale_origin_x      = x_origin_service[optimal_scale]\n",
    "    scale_origin_y      = y_origin_service[optimal_scale]\n",
    "    scale_pixel_x       = x_pixel_service[optimal_scale]\n",
    "    scale_pixel_y       = y_pixel_service[optimal_scale]\n",
    "    scale_matrix_width  = mat_width_service[optimal_scale]\n",
    "    scale_matrix_height = mat_height_service[optimal_scale]\n",
    "\n",
    "\n",
    "    # Compute tiling factors\n",
    "    factor_x = scale_pixel_size * scale_pixel_x\n",
    "    factor_y = scale_pixel_size * scale_pixel_y\n",
    "\n",
    "    # Compute ranges\n",
    "    parsing_low_x = math.floor( ( + param_bbox[0] - scale_origin_x ) / factor_x )\n",
    "    parsing_hig_x = math.ceil ( ( + param_bbox[2] - scale_origin_x ) / factor_x )\n",
    "    parsing_low_y = math.floor( ( - param_bbox[3] + scale_origin_y ) / factor_y )\n",
    "    parsing_hig_y = math.ceil ( ( - param_bbox[1] + scale_origin_y ) / factor_y )\n",
    "\n",
    "    # Query index\n",
    "    query_index = 0\n",
    "\n",
    "    # Compute composite image resolution\n",
    "    composite_w = ( parsing_hig_x - parsing_low_x + 1 ) * scale_pixel_x\n",
    "    composite_h = ( parsing_hig_y - parsing_low_y + 1 ) * scale_pixel_y\n",
    "\n",
    "    # Initialise final image\n",
    "    composite_image = Image.new( 'RGB', ( composite_w, composite_h ) )\n",
    "\n",
    "    # Parsing tiles - longitude\n",
    "    for tile_x in range( parsing_low_x, parsing_hig_x + 1 ):\n",
    "\n",
    "        # Parsing tiles - latitude\n",
    "        for tile_y in range( parsing_low_y, parsing_hig_y + 1 ):\n",
    "\n",
    "            # Push service url\n",
    "            tile_url = param_url\n",
    "\n",
    "            # Push scale in tile url\n",
    "            tile_url = tile_url.replace( '{TileMatrix}', f'{optimal_scale}' )\n",
    "\n",
    "            # Push coordinates in tile url\n",
    "            tile_url = tile_url.replace( '{TileCol}', f'{tile_x}' )\n",
    "            tile_url = tile_url.replace( '{TileRow}', f'{tile_y}' )\n",
    "\n",
    "            # Display query URL - In case of need, simply un-comment this line\n",
    "            print( tile_url )\n",
    "\n",
    "            # Perform query to service\n",
    "            query = requests.get( tile_url, allow_redirects=True, verify=False )\n",
    "\n",
    "            # Check query\n",
    "            if query.status_code == 200:\n",
    "\n",
    "                # Read image from query answer\n",
    "                temporary_image = Image.open( io.BytesIO( query.content ) )\n",
    "\n",
    "                # Copy image content at relevant location in composite image\n",
    "                composite_image.paste( temporary_image, ( ( tile_x - parsing_low_x ) * scale_pixel_x, ( tile_y - parsing_low_y ) * scale_pixel_y ) )\n",
    "\n",
    "                # Free temporary image\n",
    "                temporary_image.close()\n",
    "\n",
    "                # Update index\n",
    "                query_index = query_index + 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Display message\n",
    "                print( 'Error : query failed' )\n",
    "\n",
    "                # Abort procedure\n",
    "                sys.exit( 1 )\n",
    "\n",
    "    # Compose temporary image path\n",
    "    geotiff_temp = os.path.join( param_tmp, 'mosiac-georef.tif' )\n",
    "\n",
    "    # Query geographical fram definition\n",
    "    geotiff_frame = osr.SpatialReference()\n",
    "\n",
    "    # Select CH1903+ frame\n",
    "    geotiff_frame.ImportFromEPSG( 2056 )\n",
    "\n",
    "    # Convert PIL image to numpy array for GDAL\n",
    "    geotiff_byte = numpy.array( composite_image )\n",
    "\n",
    "    # Create geotiff container\n",
    "    geotiff_image = gdal.GetDriverByName('GTiff').Create( geotiff_temp, composite_w, composite_h, 3, gdal.GDT_Byte )\n",
    "\n",
    "    # GeoTiff transformation and projection\n",
    "    geotiff_image.SetGeoTransform( ( scale_origin_x + parsing_low_x * factor_x, scale_pixel_size, 0, scale_origin_y - parsing_low_y * factor_y, 0, -scale_pixel_size ) )\n",
    "    geotiff_image.SetProjection( geotiff_frame.ExportToWkt() )\n",
    "\n",
    "    # GeoTiff color layer\n",
    "    geotiff_image.GetRasterBand(1).WriteArray( geotiff_byte[:,:,0] )\n",
    "    geotiff_image.GetRasterBand(2).WriteArray( geotiff_byte[:,:,1] )\n",
    "    geotiff_image.GetRasterBand(3).WriteArray( geotiff_byte[:,:,2] )\n",
    "\n",
    "    # Purge and clear GeoTiff container\n",
    "    geotiff_image.FlushCache()\n",
    "    geotiff_image = None\n",
    "\n",
    "    # Final crop to get the desired tile - Not a satisfying solution, should be\n",
    "    # performed within the script to spare one temporary file\n",
    "    os.system( f\"gdalwarp -of GTiff -s_srs epsg:2056 -t_srs epsg:2056 -te {param_bbox[0]} {param_bbox[1]} {param_bbox[2]} {param_bbox[3]} -ts {param_size[0]} 0 -r cubic {geotiff_temp} {param_output}\" )\n",
    "\n",
    "    # Remove temporary file\n",
    "    os.remove( geotiff_temp )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0688356",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('03_Scripts/config.yaml') as fp:\n",
    "    cfg = yaml.load(fp, Loader=yaml.FullLoader)['wmts-geoquery.py']    #  [os.path.basename(__file__)]\n",
    "\n",
    "URL=cfg['url']\n",
    "LAYER=cfg['layer']\n",
    "TILES=cfg['tiles']\n",
    "WIDTH=cfg['width']\n",
    "TIME=cfg['time']\n",
    "TMP=cfg['tmp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99210767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsalamin/Python_env/road_surfaces/lib/python3.8/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'wmts.geo.admin.ch'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# This segment of the code is responsible of fetching the WMTS capabilities\n",
    "# files using the service URL provided as parameter. It then reads the XML\n",
    "# file in order to extract all the necessary information to perform the\n",
    "# geographical-based queries.\n",
    "#\n",
    "# It also prepare the service URL, found in the XML, by replacing the tiles\n",
    "# non-related information, such as time and layer style.\n",
    "\n",
    "# Query WMTS XML capabilities    \n",
    "service = requests.get(URL, allow_redirects=True, verify=False )\n",
    "\n",
    "# Extract XML content\n",
    "service_xml = service.content.decode(\"utf-8\")\n",
    "\n",
    "# Read XML content\n",
    "service_xml_path, service_xml_data = read_xml_thing( service_xml )\n",
    "\n",
    "# Extract layer information\n",
    "layer = detect_layer( service_xml_path, service_xml_data, LAYER )\n",
    "\n",
    "# Check layer detection\n",
    "if layer == None:\n",
    "\n",
    "    # Display message\n",
    "    print( 'Error : Unable to find layer in provided service' )\n",
    "\n",
    "    # Abort script\n",
    "    sys.exit( 1 )\n",
    "\n",
    "# Extract layer information\n",
    "layer_scales, denominator_service, x_origin_service, y_origin_service, x_pixel_service, y_pixel_service, mat_width_service, mat_height_service = detect_tile_matrix( service_xml_path, service_xml_data, layer[\"TileMatrixSet\"] )\n",
    "\n",
    "# Compose scale limits\n",
    "min_scale_service = 0\n",
    "max_scale_service = len( layer_scales ) - 1\n",
    "\n",
    "# Check matrix set detection\n",
    "if layer_scales == None:\n",
    "\n",
    "    # Display message\n",
    "    print( 'Error : Unable to locate tile matrix set of layer' )\n",
    "\n",
    "    # Abort script\n",
    "    sys.exit( 1 )\n",
    "\n",
    "# Assign query URL\n",
    "query_url = layer[\"ResourceURL\"]\n",
    "\n",
    "# Prepare ressource URL - Replace time value\n",
    "if query_url.find( '{Time}' ) != -1:\n",
    "    query_url = query_url.replace( '{Time}', TIME )\n",
    "\n",
    "# Prepare ressource URL - Replace style value\n",
    "if query_url.find( '{Style}' ) != -1:\n",
    "    query_url = query_url.replace( '{Style}', layer[\"Style\"] )\n",
    "\n",
    "# Prepare ressource URL - Replace style value\n",
    "if query_url.find( '{TileMatrixSet}' ) != -1:\n",
    "    query_url = query_url.replace( '{TileMatrixSet}', layer[\"TileMatrixSet\"] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This segment of the code reads the provided geographical file through\n",
    "# parameter and reads its content, expected to be mono-polygon. Each polygon\n",
    "# is read through its bounding box, defining a tile per polygon. The tile\n",
    "# bounding box are then sent to the WMTS/WMS converter to obtain the desired\n",
    "# geographical tile from a WMTS tile server.\n",
    "\n",
    "# Import tile geographical file - Force CH1903+ frame\n",
    "vector_tile = gpd.read_file( TILES ).to_crs( 'EPSG:2056' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d44e5ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  fid         id  datenstand resolution  \\\n",
      "818    942  943  2637_1199        2018         10   \n",
      "819    902  903  2637_1159        2018         25   \n",
      "820    902  903  2637_1159        2018         25   \n",
      "821    903  904  2637_1160        2018         25   \n",
      "822    916  917  2637_1173        2018         10   \n",
      "823    917  918  2637_1174        2018         10   \n",
      "824    932  933  2637_1189        2018         10   \n",
      "825    935  936  2637_1192        2018         10   \n",
      "826    936  937  2637_1193        2018         10   \n",
      "827    938  939  2637_1195        2018         10   \n",
      "\n",
      "                                              geometry  \n",
      "818  MULTIPOLYGON (((2637000.000 1199000.000, 26370...  \n",
      "819  MULTIPOLYGON (((2637000.000 1159000.000, 26370...  \n",
      "820  MULTIPOLYGON (((2637000.000 1159000.000, 26370...  \n",
      "821  MULTIPOLYGON (((2637000.000 1160000.000, 26370...  \n",
      "822  MULTIPOLYGON (((2637000.000 1173000.000, 26370...  \n",
      "823  MULTIPOLYGON (((2637000.000 1174000.000, 26370...  \n",
      "824  MULTIPOLYGON (((2637000.000 1189000.000, 26370...  \n",
      "825  MULTIPOLYGON (((2637000.000 1192000.000, 26370...  \n",
      "826  MULTIPOLYGON (((2637000.000 1193000.000, 26370...  \n",
      "827  MULTIPOLYGON (((2637000.000 1195000.000, 26370...  \n"
     ]
    }
   ],
   "source": [
    "print(vector_tile.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b277ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing tiles\n",
    "for index, tile in vector_tile.iterrows():\n",
    "\n",
    "    # Extract tile bounding box\n",
    "    bounding_box = tile['geometry'].bounds\n",
    "\n",
    "    # Compose bounding box array\n",
    "    tile_bbox = [ bounding_box[0], bounding_box[1], bounding_box[2], bounding_box[3] ]\n",
    "\n",
    "    # Compute tile geographical size\n",
    "    tile_geo_w = tile_bbox[2] - tile_bbox[0]\n",
    "    tile_geo_h = tile_bbox[3] - tile_bbox[1]\n",
    "\n",
    "    # Assign tile pixel width\n",
    "    tile_pixel_w = WIDTH\n",
    "\n",
    "    # Deduce tile pixel height\n",
    "    tile_pixel_h = round( tile_pixel_w * ( tile_geo_h / tile_geo_w ) )\n",
    "\n",
    "    # Compose tile size array\n",
    "    tile_size = [ tile_pixel_w, tile_pixel_h ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f4492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
