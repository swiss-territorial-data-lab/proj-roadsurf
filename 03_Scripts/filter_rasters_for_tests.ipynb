{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script allows to filter rasters to test some result and functions.\n",
    "\n",
    "- based on pixel values so we can visualize the extrem pixels and look out for anomaly\n",
    "- to test the mask function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import logging, logging.config\n",
    "import yaml\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import shapes\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import fct_misc\n",
    "\n",
    "from helpers import XYZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILES_DIR='/mnt/data-01/gsalamin/proj-roadsurf-b/02_Data/processed/obj_detector/all-images'\n",
    "ROADS='/mnt/data-01/gsalamin/proj-roadsurf-b/02_Data/processed/shapefiles_gpkg/roads_polygons.shp'\n",
    "TILES_INFO='/mnt/data-01/gsalamin/proj-roadsurf-b/02_Data/processed/json/tiles_aoi.geojson'\n",
    "\n",
    "roads=gpd.read_file(ROADS)\n",
    "tiles_info=gpd.read_file(TILES_INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing extrem values\n",
    "## Making polygons on the zones to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob.glob(TILES_DIR+'/*.tif')\n",
    "print(files[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom=[]\n",
    "bands=[]\n",
    "pixel_values=[]\n",
    "\n",
    "for file in tqdm(files, desc='Checking files'):\n",
    "    for band in range(1,5):\n",
    "        with rasterio.open(file) as f:\n",
    "            image = f.read(band)\n",
    "\n",
    "            lim_sup=200\n",
    "            lim_inf=1\n",
    "\n",
    "            # create a binary image, 0 where there's nodata, 1 where it's valid\n",
    "            is_valid = ((image < lim_inf) | (image > lim_sup)).astype(np.uint8)\n",
    "\n",
    "            \n",
    "            # vectorize the binary image, supplying the transform so it returns maps coords\n",
    "            for coords, value in shapes(is_valid, transform=f.transform):\n",
    "\n",
    "                # ignore polygons corresponding to nodata\n",
    "                if value != 0:\n",
    "                    # convert geojson to shapely geometry\n",
    "                    geom.append(shape(coords))\n",
    "                    bands.append(band)\n",
    "                    pixel_values.append(value)\n",
    "\n",
    "fid=[x for x in range(1, len(geom)+1)]\n",
    "zones_dict={'fid':fid, 'band':bands, 'pixel_value':pixel_values, 'geometry': geom}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrem_zones=gpd.GeoDataFrame(zones_dict, crs='EPSG:3857')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_reproject=roads.to_crs(epsg=3857)\n",
    "\n",
    "misc_fct.test_crs(roads_reproject.crs, extrem_zones.crs)\n",
    "\n",
    "extrem_zones_on_roads=gpd.overlay(extrem_zones,roads_reproject[['OBJECTID', 'geometry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrem_zones_on_roads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrem_zones_on_roads.drop_duplicates(subset=['fid'], inplace=True, ignore_index=True)\n",
    "\n",
    "extrem_zones_on_roads.to_file('/mnt/data-01/gsalamin/proj-roadsurf-b/02_Data/processed/shapefiles_gpkg/test_extrem_pixels.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrem_zones_on_roads.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading tiles for the zones to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as fp:\n",
    "    cfg = yaml.load(fp, Loader=yaml.FullLoader)['generate_tilesets.py']\n",
    "\n",
    "OUTPUT_DIR = '/mnt/data-01/gsalamin/proj-roadsurf-b/02_Data/processed/images'\n",
    "\n",
    "ORTHO_WS_TYPE = cfg['datasets']['orthophotos_web_service']['type']\n",
    "ORTHO_WS_URL = cfg['datasets']['orthophotos_web_service']['url']\n",
    "ORTHO_WS_SRS = cfg['datasets']['orthophotos_web_service']['srs']\n",
    "if 'layers' in cfg['datasets']['orthophotos_web_service'].keys():\n",
    "    ORTHO_WS_LAYERS = cfg['datasets']['orthophotos_web_service']['layers']\n",
    "if 'parameters' in cfg['datasets']['orthophotos_web_service'].keys():\n",
    "    ORTHO_WS_PARAMETERS=cfg['datasets']['orthophotos_web_service']['parameters']\n",
    "else:\n",
    "    ORTHO_WS_PARAMETERS={}\n",
    "\n",
    "SAVE_METADATA = True\n",
    "OVERWRITE = cfg['overwrite']\n",
    "TILE_SIZE = cfg['tile_size']\n",
    "\n",
    "ALL_IMG_PATH = os.path.join(OUTPUT_DIR, f\"test\")\n",
    "if not os.path.exists(ALL_IMG_PATH):\n",
    "        os.makedirs(ALL_IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_info_reproj=tiles_info.to_crs(crs=3857)\n",
    "\n",
    "misc_fct.test_crs(tiles_info_reproj.crs, extrem_zones_on_roads.crs)\n",
    "\n",
    "tiles_info_on_zones=gpd.overlay(tiles_info_reproj, extrem_zones_on_roads[['fid','geometry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_info_on_zones.drop_duplicates(subset=['id'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dict = XYZ.get_job_dict(\n",
    "    tiles_gdf=tiles_info_on_zones.to_crs(ORTHO_WS_SRS), # <- note the reprojection\n",
    "    XYZ_url=ORTHO_WS_URL, \n",
    "    img_path=ALL_IMG_PATH, \n",
    "    save_metadata=SAVE_METADATA,\n",
    "    overwrite=OVERWRITE\n",
    ")\n",
    "\n",
    "image_getter = XYZ.get_geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings(record=True):\n",
    "    N_JOBS=10\n",
    "    job_outcome = Parallel(n_jobs=N_JOBS, backend=\"loky\")(\n",
    "                delayed(image_getter)(**v) for k, v in tqdm( sorted(list(job_dict.items())) )\n",
    "        )\n",
    "\n",
    "    all_tiles_were_downloaded = True\n",
    "    for job in job_dict.keys():\n",
    "        if not os.path.isfile(job) or not os.path.isfile(job.replace('.tif', '.json')):\n",
    "            all_tiles_were_downloaded = False\n",
    "            print('Failed task: ', job)\n",
    "\n",
    "    if all_tiles_were_downloaded:\n",
    "        print(\"...done.\")\n",
    "    else:\n",
    "        print(\"Some tiles were not downloaded. Please try to run this script again.\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 84 invalid geometries for the roads after the reprojection.\n",
      "Correction of the roads presenting an invalid geometry with a buffer of 0 m...\n"
     ]
    }
   ],
   "source": [
    "if roads[roads.is_valid==False].shape[0]!=0:\n",
    "        print(f\"There are {roads[roads.is_valid==False].shape[0]} invalid geometries for the roads.\")\n",
    "        sys.exit(1)          \n",
    "\n",
    "simplified_roads=roads.drop(columns=['ERSTELLUNG', 'ERSTELLU_1', 'HERKUNFT', 'HERKUNFT_J', 'HERKUNFT_M',\n",
    "        'KUNSTBAUTE', 'WANDERWEGE', 'VERKEHRSBE', 'BEFAHRBARK', 'EROEFFNUNG', 'STUFE', 'RICHTUNGSG',\n",
    "        'KREISEL', 'EIGENTUEME', 'VERKEHRS_1', 'NAME', 'TLM_STRASS', 'STRASSENNA', 'SHAPE_Leng'])\n",
    "\n",
    "roads_reproj=simplified_roads.to_crs(epsg=3857)\n",
    "tiles_info_reproj=tiles_info.to_crs(epsg=3857)\n",
    "\n",
    "fp_list=[]\n",
    "for tile_idx in tiles_info_reproj['id'].values:\n",
    "        # Get the name of the tiles\n",
    "        x, y, z = tile_idx.lstrip('(,)').rstrip('(,)').split(',')\n",
    "        im_name = z.lstrip() + '_' + x + '_' + y.lstrip() + '.tif'\n",
    "        im_path = os.path.join(TILES_DIR, im_name)\n",
    "        fp_list.append(im_path)\n",
    "\n",
    "tiles_info_reproj['filepath']=fp_list\n",
    "\n",
    "fct_misc.test_crs(roads_reproj.crs, tiles_info_reproj.crs)\n",
    "\n",
    "if roads_reproj[roads_reproj.is_valid==False].shape[0]!=0:\n",
    "        print(f\"There are {roads_reproj[roads_reproj.is_valid==False].shape[0]} invalid geometries for the roads after the reprojection.\")\n",
    "\n",
    "print(\"Correction of the roads presenting an invalid geometry with a buffer of 0 m...\")\n",
    "corrected_roads=roads_reproj.copy()\n",
    "corrected_roads.loc[corrected_roads.is_valid==False,'geometry']=corrected_roads[corrected_roads.is_valid==False]['geometry'].buffer(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fct_misc.test_crs(corrected_roads.crs, tiles_info_reproj.crs)\n",
    "intersected_tiles=gpd.sjoin(tiles_info_reproj, corrected_roads[['OBJECTID', 'geometry']])\n",
    "intersected_tiles.drop_duplicates(subset=['id','OBJECTID'], inplace=True)\n",
    "\n",
    "try:\n",
    "    assert not corrected_roads['OBJECTID'].duplicated().any()\n",
    "except:\n",
    "    print('Some roads are separated on mulitple lines. They must be transformed to multipolygons or fused first.')\n",
    "    sys.exit(1)\n",
    "\n",
    "pixels_per_band=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS=range(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.51 ms ± 193 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "pixels_per_band=pd.DataFrame()\n",
    "objectid=corrected_roads.OBJECTID[0]\n",
    "\n",
    "# Get the corresponding tile(s)\n",
    "intersected_tiles_with_road=intersected_tiles[intersected_tiles['OBJECTID'] == objectid].copy()\n",
    "intersected_tiles_with_road.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get the pixels for each tile\n",
    "for tile_filepath in intersected_tiles_with_road['filepath'].values:\n",
    "    pixel_values=pd.DataFrame()\n",
    "    \n",
    "    # extract the geometry in GeoJSON format\n",
    "    geoms = [mapping(corrected_roads.geometry[0])]\n",
    "\n",
    "    # extract the raster values values within the polygon \n",
    "    with rasterio.open(tile_filepath) as src:\n",
    "        out_image, _ = mask(src, geoms, crop=True)\n",
    "\n",
    "        # no data values of the original raster\n",
    "        no_data=src.nodata\n",
    "\n",
    "    dico={}\n",
    "    length_bands=[]\n",
    "    for band in BANDS:\n",
    "\n",
    "        # extract the values of the masked array\n",
    "        data = out_image[band-1]\n",
    "\n",
    "        # extract the the valid values\n",
    "        val = np.extract(data != no_data, data)\n",
    "\n",
    "        dico[f'band{band}']=val\n",
    "        length_bands.append(len(val))\n",
    "\n",
    "    dico.update({'road_id': objectid})\n",
    "    pixels_from_tile = pd.DataFrame(dico)\n",
    "\n",
    "    pixel_values = pd.concat([pixel_values, pixels_from_tile],ignore_index=True)\n",
    "\n",
    "pixels_per_band=pd.concat([pixels_per_band, pixel_values], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 87, 86,  0,  0],\n",
       "       [ 0,  0,  0,  0, 89, 88, 88,  0],\n",
       "       [ 0,  0,  0, 86, 87, 88, 89,  0],\n",
       "       [ 0,  0,  0, 79, 84, 87, 88,  0],\n",
       "       [ 0,  0, 78, 79, 79, 81,  0,  0],\n",
       "       [ 0, 78, 74, 77, 80, 79,  0,  0],\n",
       "       [ 0, 82, 78, 77, 75,  0,  0,  0],\n",
       "       [ 0,  0,  0, 79, 80,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0]], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_image[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256%256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('road_surfaces')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d832f3481d940cc3bb935f7c66bfbdcf68066e3553491dd3c1b68c49468b7cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
